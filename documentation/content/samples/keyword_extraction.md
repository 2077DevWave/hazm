در این مثال قصد داریم با کمک هضم و برخی از کتابخانه‌های پردازش زبان، کلمات کلیدی یک متن را استخراج کنیم. در تمام الگوریتم‌های استخراج کلمات کلیدی، ابتدا باید متن خام 
ورودی نرمال‌سازی، توکنایز و برچسب‌گذاری شود که انجام این کارها به سادگی توسط کتابخانهٔ هضم میسر است.

ابتدا آخرین نسخهٔ هضم و تمام کتابخانه‌هایی را که در مثال زیر ایمپورت شده‌اند نصب کنید.


```python
pip install hazm
```


```python
import numpy as np
import nltk
import re
import string
import warnings
import gensim
from sklearn.metrics.pairwise import cosine_similarity
from configparser import ConfigParser
from functools import reduce
from gensim.models import Doc2Vec
from hazm.Embedding import SentEmbedding
from hazm import * 
```

متنی را برای استخراج کلمات کلیدی آن در نظر بگیرید.


```python
text = 'سفارت ایران در مادرید درباره فیلم منتشرشده از «حسن قشقاوی» در مراسم سال نو در کاخ سلطنتی اسپانیا و حاشیه‌سازی‌ها در فضای مجازی اعلام کرد: به تشریفات دربار کتباً اعلام شد سفیر بدون همراه در مراسم حضور خواهد داشت و همچون قبل به دلایل تشریفاتی نمی‌تواند با ملکه دست بدهد. همان‌گونه که کارشناس رسمی تشریفات در توضیحات خود به یک نشریه اسپانیایی گفت این موضوع توضیح مذهبی داشته و هرگز به معنی بی‌احترامی به مقام و شخصیت زن آن هم در سطح ملکه محترمه یک کشور نیست.'

keyword_count = 10
```

## نرمال‌سازی متن و استخراج توکن‌ها توسط هضم
متن ورودی را با کمک نرمالایزر هضم نرمال‌سازی می‌کنیم و پس از آن با کمک توکنایزر به جملات و در نهایت به کلمات می‌شکنیم.


```python
normalizer = Normalizer()
normalize_text = normalizer.normalize(text)
tokenize_text = [word_tokenize(txt) for txt in sent_tokenize(normalize_text)]
tokenize_text
```




    [['سفارت',
      'ایران',
      'در',
      'مادرید',
      'درباره',
      'فیلم',
      'منتشرشده',
      'از',
      '«',
      'حسن',
      'قشقاوی',
      '»',
      'در',
      'مراسم',
      'سال',
      'نو',
      'در',
      'کاخ',
      'سلطنتی',
      'اسپانیا',
      'و',
      'حاشیه‌سازی‌ها',
      'در',
      'فضای',
      'مجازی',
      'اعلام',
      'کرد',
      ':',
      'به',
      'تشریفات',
      'دربار',
      'کتبا',
      'اعلام',
      'شد',
      'سفیر',
      'بدون',
      'همراه',
      'در',
      'مراسم',
      'حضور',
      'خواهد_داشت',
      'و',
      'همچون',
      'قبل',
      'به',
      'دلایل',
      'تشریفاتی',
      'نمی‌تواند',
      'با',
      'ملکه',
      'دست',
      'بدهد',
      '.'],
     ['همان‌گونه',
      'که',
      'کارشناس',
      'رسمی',
      'تشریفات',
      'در',
      'توضیحات',
      'خود',
      'به',
      'یک',
      'نشریه',
      'اسپانیایی',
      'گفت',
      'این',
      'موضوع',
      'توضیح',
      'مذهبی',
      'داشته',
      'و',
      'هرگز',
      'به',
      'معنی',
      'بی‌احترامی',
      'به',
      'مقام',
      'و',
      'شخصیت',
      'زن',
      'آن',
      'هم',
      'در',
      'سطح',
      'ملکه',
      'محترمه',
      'یک',
      'کشور',
      'نیست',
      '.']]



## استخراج تگ POS برای هر یک از کلمات
بعد از لودکردن مدل POS، هر یک از کلمات را با ماژول POSTagger هضم برچسب‌گذاری می‌کنیم.


```python
model_path = '/resources/POSTagger.model'
tagger = POSTagger(model = model_path)
token_tag_list = tagger.tag_sents(tokenize_text)
token_tag_list
```




    [[('سفارت', 'NOUN,EZ'),
      ('ایران', 'NOUN'),
      ('در', 'ADP'),
      ('مادرید', 'NOUN'),
      ('درباره', 'ADP,EZ'),
      ('فیلم', 'NOUN,EZ'),
      ('منتشرشده', 'ADJ'),
      ('از', 'ADP'),
      ('«', 'PUNCT'),
      ('حسن', 'NOUN,EZ'),
      ('قشقاوی', 'NOUN'),
      ('»', 'PUNCT'),
      ('در', 'ADP'),
      ('مراسم', 'NOUN,EZ'),
      ('سال', 'NOUN,EZ'),
      ('نو', 'ADJ'),
      ('در', 'ADP'),
      ('کاخ', 'NOUN,EZ'),
      ('سلطنتی', 'ADJ,EZ'),
      ('اسپانیا', 'NOUN'),
      ('و', 'CCONJ'),
      ('حاشیه‌سازی‌ها', 'NOUN'),
      ('در', 'ADP'),
      ('فضای', 'NOUN,EZ'),
      ('مجازی', 'ADJ'),
      ('اعلام', 'NOUN'),
      ('کرد', 'VERB'),
      (':', 'PUNCT'),
      ('به', 'ADP'),
      ('تشریفات', 'NOUN,EZ'),
      ('دربار', 'NOUN,EZ'),
      ('کتبا', 'ADV'),
      ('اعلام', 'NOUN'),
      ('شد', 'VERB'),
      ('سفیر', 'NOUN'),
      ('بدون', 'ADP,EZ'),
      ('همراه', 'NOUN'),
      ('در', 'ADP'),
      ('مراسم', 'NOUN'),
      ('حضور', 'NOUN'),
      ('خواهد_داشت', 'VERB'),
      ('و', 'CCONJ'),
      ('همچون', 'ADV'),
      ('قبل', 'ADP'),
      ('به', 'ADP'),
      ('دلایل', 'NOUN,EZ'),
      ('تشریفاتی', 'ADJ'),
      ('نمی‌تواند', 'VERB'),
      ('با', 'ADP'),
      ('ملکه', 'NOUN'),
      ('دست', 'NOUN'),
      ('بدهد', 'VERB'),
      ('.', 'PUNCT')],
     [('همان‌گونه', 'NOUN'),
      ('که', 'SCONJ'),
      ('کارشناس', 'NOUN,EZ'),
      ('رسمی', 'ADJ,EZ'),
      ('تشریفات', 'NOUN'),
      ('در', 'ADP'),
      ('توضیحات', 'NOUN,EZ'),
      ('خود', 'PRON'),
      ('به', 'ADP'),
      ('یک', 'NUM'),
      ('نشریه', 'NOUN,EZ'),
      ('اسپانیایی', 'ADJ'),
      ('گفت', 'VERB'),
      ('این', 'DET'),
      ('موضوع', 'NOUN'),
      ('توضیح', 'NOUN,EZ'),
      ('مذهبی', 'ADJ'),
      ('داشته', 'VERB'),
      ('و', 'CCONJ'),
      ('هرگز', 'ADV'),
      ('به', 'ADP'),
      ('معنی', 'NOUN,EZ'),
      ('بی‌احترامی', 'NOUN'),
      ('به', 'ADP'),
      ('مقام', 'NOUN'),
      ('و', 'CCONJ'),
      ('شخصیت', 'NOUN,EZ'),
      ('زن', 'NOUN,EZ'),
      ('آن', 'PRON'),
      ('هم', 'CCONJ'),
      ('در', 'ADP'),
      ('سطح', 'NOUN,EZ'),
      ('ملکه', 'NOUN,EZ'),
      ('محترمه', 'ADJ,EZ'),
      ('یک', 'NUM'),
      ('کشور', 'NOUN'),
      ('نیست', 'VERB'),
      ('.', 'PUNCT')]]



## استخراج کاندیداها
با استفاده از چند گرامر، کاندیداها را پیدا می‌کنیم.


```python
grammers = [
"""
NP:
        {<NOUN,EZ>?<NOUN.*>}    # Noun(s) + Noun(optional) 
        
""",

"""
NP:
        {<NOUN.*><ADJ.*>?}    # Noun(s) + Adjective(optional) 
        
"""
]
## you can also add your own grammer to be extracted from the text...
```


```python
def extract_candidates(tagged, grammer):
    keyphrase_candidate = set()
    np_parser = nltk.RegexpParser(grammer)
    trees = np_parser.parse_sents(tagged)
    for tree in trees:
        for subtree in tree.subtrees(filter=lambda t: t.label() == 'NP'):  # For each nounphrase
            # Concatenate the token with a space
            keyphrase_candidate.add(' '.join(word for word, tag in subtree.leaves()))
    keyphrase_candidate = {kp for kp in keyphrase_candidate if len(kp.split()) <= 5}
    keyphrase_candidate = list(keyphrase_candidate)
    return keyphrase_candidate    

all_candidates = set()
for grammer in grammers:
    all_candidates.update(extract_candidates(token_tag_list, grammer))


all_candidates = np.array(list(all_candidates))


print(np.array(list(all_candidates)))

```

    ['مقام' 'توضیح' 'اسپانیا' 'ملکه محترمه' 'توضیح مذهبی' 'ملکه'
     'تشریفات دربار' 'معنی بی‌احترامی' 'توضیحات' 'دلایل' 'سفارت' 'کشور'
     'فضای' 'مراسم' 'موضوع' 'سفارت ایران' 'حاشیه‌سازی‌ها' 'ایران'
     'شخصیت زن' 'بی‌احترامی' 'سطح' 'حضور' 'سال نو' 'دست' 'دلایل تشریفاتی'
     'نشریه اسپانیایی' 'سفیر' 'حسن' 'کارشناس رسمی' 'فیلم' 'کارشناس'
     'مراسم سال' 'مادرید' 'تشریفات' 'کاخ' 'معنی' 'فیلم منتشرشده' 'سطح ملکه'
     'کاخ سلطنتی' 'همان‌گونه' 'دربار' 'اعلام' 'زن' 'حسن قشقاوی' 'نشریه'
     'قشقاوی' 'فضای مجازی' 'همراه' 'شخصیت']


## لودکردن مدل Sent2Vec
مدل sent2vec را لود می‌کنیم.


```python
sent2vec_model_path = '/resources/sent2vec.model'
sent2vec_model = SentEmbedding(sent2vec_model_path)
```

## استخراج وکتور برای هر یک از کاندیداها و کل متن
با کمک مدلی که در مرحله قبل لود شد هر یک از کاندیداها را به وکتور متناظر تبدیل می‌کنیم و همانند آن یکبار هم با ترکیب تمام کاندیداهای یک وکتور، به عنوان وکتور نمایندهٔ متن تعیین می‌کنیم.  


```python
all_candidates_vectors = [sent2vec_model[candidate] for candidate in all_candidates]
all_candidates_vectors[0:2]
```




    [array([-0.01188162, -0.01629335, -0.02919522, -0.00783677, -0.00102758,
            -0.03208233, -0.01709846,  0.0117062 ,  0.03449516,  0.07738346,
             0.00717299, -0.01352314, -0.01112981,  0.03587793,  0.02290764,
             0.02365053, -0.04915352,  0.03136308,  0.02879261, -0.0384808 ,
             0.02003807,  0.08317484, -0.04286249, -0.00853691,  0.0007173 ,
            -0.02911104, -0.06039644,  0.05314305,  0.08562349, -0.01360018,
             0.0557404 , -0.02959855, -0.06252556,  0.05031461, -0.01516408,
            -0.04968432,  0.04772092, -0.01781998,  0.0710771 , -0.00372977,
             0.00765758,  0.00515331,  0.00598954, -0.0136055 ,  0.01701651,
             0.01654306, -0.04593932,  0.01149338,  0.04326366, -0.0027622 ,
            -0.03415394,  0.05197985,  0.00967025, -0.03596427, -0.03119466,
             0.02795039, -0.01621666, -0.02909403, -0.02455824, -0.03838604,
             0.01372122, -0.02214047,  0.02800225, -0.0036714 , -0.00367276,
            -0.02312022, -0.01213884,  0.01923293, -0.0138466 ,  0.0245442 ,
             0.02510322, -0.02143596,  0.01493786, -0.02484095, -0.01944517,
             0.05156582,  0.02139942,  0.02890227, -0.01623013, -0.05854516,
             0.01643235, -0.03991502,  0.02022447,  0.01189267,  0.01317829,
             0.02556234, -0.01462544, -0.00787411, -0.01378851, -0.00172833,
             0.06837806, -0.01764285,  0.06281603, -0.01626222,  0.02556866,
             0.0185748 , -0.0067836 , -0.05015644, -0.01342974,  0.02539523,
            -0.01581901, -0.02425192,  0.0452649 , -0.00750458,  0.0967936 ,
            -0.05387386, -0.0530752 , -0.03162006, -0.00527164, -0.00276   ,
            -0.01255972, -0.04338565,  0.02156437,  0.001823  , -0.01073027,
             0.01847384, -0.01646022,  0.02929114, -0.00578533, -0.02494396,
             0.0087481 ,  0.01070363,  0.0446781 , -0.01213747,  0.0204882 ,
             0.01355058, -0.01376898,  0.05580157,  0.0251492 , -0.00559421,
             0.05595972, -0.00807772, -0.00067975, -0.03694296, -0.01427727,
            -0.02566851, -0.05726627, -0.06947549, -0.00970706,  0.03093396,
            -0.02401018, -0.02033974,  0.04390932,  0.0235374 , -0.02385219,
            -0.0382009 ,  0.06009208, -0.00510711,  0.05597803,  0.00266409,
             0.00551957,  0.01635106, -0.03252611, -0.03596902, -0.00345108,
             0.01352903, -0.04293061, -0.05658675,  0.06818494,  0.01084052,
            -0.0122018 ,  0.03576101,  0.00328646,  0.03027316, -0.01719276,
            -0.04367308,  0.03075343, -0.03755889,  0.00605542,  0.02004578,
             0.00340594,  0.01712043, -0.016981  ,  0.05374645,  0.00200974,
            -0.03294465,  0.04005791,  0.00457313, -0.01694714,  0.01113838,
            -0.01993673, -0.01606067,  0.03990012,  0.0253757 , -0.00950528,
             0.01274851, -0.01169313, -0.01289013, -0.01327011, -0.01994459,
            -0.04132632, -0.02350255, -0.01223114,  0.07291141, -0.00721371,
            -0.07875457,  0.00083011,  0.00684158, -0.05026994,  0.01031176,
             0.02373392,  0.03969928,  0.01638419, -0.03867376, -0.0687755 ,
            -0.01340831, -0.02255411, -0.0149805 ,  0.03496141,  0.02445213,
             0.01440182, -0.00022292, -0.00643517,  0.05528902, -0.00860113,
            -0.06000795,  0.04228028, -0.01444338,  0.00576453,  0.01684438,
            -0.01549434, -0.01222704,  0.01536382, -0.0287157 , -0.04939798,
             0.03567187, -0.05428684, -0.01057596, -0.00523087, -0.00397995,
            -0.04025532, -0.02501184, -0.05732642, -0.0331133 , -0.00092318,
            -0.03302578, -0.0284121 ,  0.04260454, -0.00608311, -0.02456535,
             0.03953174,  0.00345775,  0.0538222 , -0.01100798,  0.04303414,
            -0.02364497, -0.08066952,  0.00375242, -0.01103138, -0.03017887,
            -0.09796415,  0.00921125,  0.05321204, -0.02509299, -0.03102512,
            -0.05872759, -0.01289234,  0.02453171,  0.00230233,  0.00488943,
            -0.01761841, -0.00174712, -0.00661878,  0.03181373, -0.04850807,
            -0.00707506, -0.0349974 ,  0.03866537, -0.00474136,  0.01659487,
             0.0594902 , -0.00231924,  0.00096324, -0.01005271,  0.05310801,
            -0.02776042,  0.02169719, -0.00060658,  0.03078633, -0.00852389,
             0.0055141 , -0.00418154, -0.04047189, -0.00518277,  0.06997076,
             0.01247645,  0.03207724,  0.0086117 ,  0.04791804, -0.0459297 ,
            -0.04185048,  0.02209319, -0.01489274, -0.00096468,  0.03030732,
             0.00811978,  0.01588543,  0.00286602, -0.0305667 , -0.03791318],
           dtype=float32),
     array([ 1.61259193e-02, -2.24474519e-02, -3.80111709e-02,  2.28938404e-02,
             1.09725883e-02,  3.17719281e-02,  6.31656572e-02,  8.05895310e-03,
            -3.53254005e-02, -1.86222717e-02,  4.08435427e-02,  1.67486863e-03,
            -2.47621853e-02,  3.77383642e-02,  3.37502137e-02,  3.93473580e-02,
             2.38729995e-02, -9.84842610e-03, -4.05367874e-02, -1.37408227e-02,
             4.74064574e-02,  3.14173172e-03, -6.56105811e-03,  5.09371283e-04,
            -4.29384643e-03,  3.29073286e-03, -2.15584543e-02,  5.68162464e-03,
            -1.66979544e-02, -1.84549782e-02,  2.46190634e-02,  3.47545161e-03,
             3.08716279e-02,  5.02820574e-02,  2.44595818e-02, -3.07906978e-02,
            -7.40932208e-03, -4.51853164e-02,  1.66600700e-02, -1.01724509e-02,
            -3.62079367e-02,  1.51233776e-02, -9.31378547e-03,  1.26175648e-02,
            -7.64256269e-02,  3.31216864e-02, -1.85449794e-02, -2.94767078e-02,
            -3.93361785e-02,  1.24856019e-02,  1.26723386e-02,  2.16722433e-02,
            -1.14210444e-02, -2.07549557e-02,  1.36339143e-02, -1.38463574e-02,
             1.06643150e-02, -1.01469979e-02,  2.93516796e-02,  9.60155949e-03,
             1.22689735e-02,  4.08919603e-02,  9.78052337e-03,  4.25264006e-05,
            -2.53092498e-02, -1.14650708e-02,  3.55252065e-04,  3.56378034e-02,
             3.77339800e-03,  3.29325721e-02,  3.37304510e-02, -4.21778522e-02,
             7.58386077e-03,  3.34312394e-03, -2.34390255e-02,  4.45654336e-03,
            -4.01547318e-03, -1.37788076e-02,  5.44098429e-02,  2.10932754e-02,
             1.08978506e-02, -4.35097292e-02,  5.21442480e-02,  5.11527397e-02,
            -2.04837527e-02,  8.39341432e-03,  4.85086218e-02,  1.83619317e-02,
            -6.74439818e-02, -2.07678247e-02,  2.59952177e-03, -5.99921905e-02,
            -4.64598276e-02, -5.67924567e-02,  2.63284668e-02,  4.18948568e-02,
             8.77644960e-03,  2.32700463e-02, -4.69084218e-04, -3.99603210e-02,
            -3.66844982e-03, -4.19982858e-02,  5.26686348e-02,  7.80321285e-03,
             5.45849465e-03, -3.21091115e-02,  1.48136532e-02, -1.08047845e-02,
             6.18305476e-03, -3.27244541e-03, -2.21317764e-02, -2.81676892e-02,
             2.93632448e-02,  2.34199744e-02, -3.65932249e-02,  5.99884167e-02,
             4.23262753e-02, -6.37584599e-03,  1.18953157e-02, -3.98992002e-02,
             8.21764022e-02,  6.34778515e-02,  5.80455083e-03,  4.27116267e-02,
            -1.33993533e-02, -2.12867167e-02, -1.75663619e-03,  1.38958599e-02,
             2.04161946e-02, -1.98126342e-02, -2.37677116e-02,  2.20986288e-02,
            -2.11866628e-02, -7.54425004e-02,  2.83495197e-03,  4.04435098e-02,
            -2.16520559e-02, -1.57567412e-02, -4.30966169e-02,  3.07689384e-02,
            -3.34076933e-03,  4.64651966e-03, -2.71396097e-02,  5.72864786e-02,
             1.92495678e-02, -2.27472223e-02, -2.72661005e-03, -1.49670069e-03,
            -2.65399162e-02, -3.39104868e-02,  1.88349164e-03,  3.54786664e-02,
            -3.47826071e-02, -6.91301599e-02,  1.59207906e-03, -2.85722595e-02,
            -3.60434540e-02, -3.22819352e-02,  4.15584631e-02, -1.40359988e-02,
             2.60002650e-02,  3.70233804e-02, -3.68171483e-02, -3.38851882e-04,
             1.03969611e-02,  5.47843752e-03, -1.22256344e-02, -5.46388812e-02,
            -1.76120512e-02,  5.58832334e-03, -3.96850007e-03, -3.92588265e-02,
            -1.55795477e-02, -1.74091645e-02, -2.05926299e-02, -3.58914435e-02,
             4.86572925e-03, -6.49047866e-02,  7.77042191e-03, -3.95775437e-02,
            -3.77140641e-02, -8.92203860e-03, -5.86874178e-03,  1.78200230e-02,
            -3.00387219e-02,  1.41944112e-02, -1.26480032e-02,  8.37522838e-03,
             6.40433095e-03,  1.28734531e-02,  3.11341765e-03, -1.25999823e-02,
             6.48253690e-03, -6.21253327e-02, -1.07876705e-02,  1.52199538e-02,
             3.34009062e-03, -1.37483543e-02, -2.59680673e-03,  2.30002590e-02,
             1.48606775e-02,  3.37255634e-02,  1.18859601e-03, -1.26267644e-02,
            -6.23443313e-02,  1.05426302e-02, -1.16890691e-01,  6.32693470e-02,
             8.37623328e-03, -5.21574169e-02, -1.24192918e-02,  1.28806029e-02,
            -2.46884692e-02,  1.09140491e-02,  3.90921719e-02,  4.26316336e-02,
             5.07211946e-02, -1.98766068e-02,  1.80651341e-03,  2.71296687e-03,
            -6.57337978e-02,  2.03521047e-02, -1.23877386e-02, -6.88543485e-04,
             1.29983081e-02,  4.26853262e-02, -4.82731014e-02,  5.27809700e-03,
             1.24023827e-02,  1.13279969e-02,  3.95294325e-03, -4.58956845e-02,
            -1.52627397e-02,  1.48914512e-02, -4.32942901e-03,  2.87926253e-02,
            -2.14931779e-02, -9.98509675e-03,  4.22625057e-02,  8.89317226e-03,
            -6.50819624e-04,  1.49660220e-03,  1.18057523e-03,  2.92290677e-03,
             2.30702627e-02, -9.86105949e-03,  3.34995277e-02,  3.97632718e-02,
             8.42674263e-03,  1.57389920e-02, -3.15342695e-02, -1.74464211e-02,
            -2.75895614e-02,  2.13450920e-02,  5.23088090e-02,  1.44411633e-02,
            -6.59985235e-03, -2.57882383e-02,  1.64036956e-02,  2.44096126e-02,
            -6.84994971e-03, -2.85031367e-02,  5.74258752e-02,  3.78873944e-02,
            -2.49026623e-02, -4.18873550e-03, -9.72696953e-03,  9.08288348e-04,
            -1.96612123e-02, -1.12741981e-02,  6.91469610e-02,  4.23650108e-02,
            -2.32512038e-02, -1.41811147e-02,  3.53554904e-04,  1.42879663e-02,
             1.52949486e-02,  1.94263272e-02,  4.98711737e-03,  2.58604288e-02,
             8.07583041e-04,  1.84617136e-02, -2.12450395e-03,  1.10163295e-03,
             4.63078031e-04,  2.57978961e-03, -5.59910526e-03, -3.86752374e-02,
             2.02463642e-02, -1.84897278e-02,  1.78292543e-02,  5.31280087e-03,
             1.04076657e-02, -1.76131763e-02,  1.36526041e-02, -3.16180114e-04,
             1.66201517e-02, -2.28249431e-02, -5.76155819e-02,  1.91252027e-02],
           dtype=float32)]




```python
 
candidates_concatinate = ' '.join(all_candidates)
whole_text_vector = sent2vec_model[candidates_concatinate]
whole_text_vector
```




    array([ 4.67376083e-01,  1.41185641e-01, -4.01345827e-02,  8.06454271e-02,
            2.87257284e-01, -1.73859105e-01,  2.10984781e-01, -4.19053972e-01,
            5.07716499e-02,  1.81625992e-01,  2.94933677e-01, -8.55805278e-02,
            1.48084328e-01, -9.41419080e-02,  5.89552283e-01,  3.02299976e-01,
           -4.53922212e-01,  8.01923499e-02, -8.41862783e-02,  2.84251839e-01,
            2.46634156e-01,  1.53678849e-01, -3.66186112e-01,  5.90183679e-03,
           -1.70991004e-01, -4.96781468e-01, -1.27169549e-01,  5.82241416e-02,
            1.20417640e-01,  4.94717717e-01,  5.77962518e-01,  1.18188798e-01,
           -6.67512298e-01,  5.29394031e-01, -7.98275769e-02, -1.44854588e-02,
           -3.16317052e-01, -1.98610872e-01, -1.48992175e-02,  9.87645239e-02,
           -3.27269435e-02,  1.41058192e-01, -2.29777753e-01, -1.86174229e-01,
           -2.49014020e-01,  5.10655567e-02, -3.53054017e-01,  9.72972959e-02,
           -4.69784170e-01,  1.05591603e-01, -1.02906279e-01, -3.80217880e-01,
           -6.22809350e-01, -3.72316897e-01,  3.62496346e-01, -6.20689332e-01,
           -3.47774744e-01,  3.33177954e-01, -3.97790000e-02,  2.65603602e-01,
           -3.18654068e-02,  2.06118658e-01,  6.80918157e-01,  2.35603571e-01,
            6.08658373e-01,  2.30967417e-01,  2.18739480e-01,  4.28926438e-01,
            5.95629275e-01,  7.48399124e-02,  2.33383089e-01, -5.90643585e-02,
           -1.44794971e-01, -2.44355276e-01,  1.19658187e-02, -6.11210883e-01,
           -4.93510604e-01,  3.08846384e-01,  2.36394048e-01,  1.40831068e-01,
            2.57682931e-02, -5.83631277e-01,  2.25270651e-02, -4.18923259e-01,
            1.24322265e-01,  1.31361187e-01,  1.88170344e-01,  6.02326691e-01,
           -1.89337790e-01,  1.94994032e-01,  1.28665030e-01, -3.76140147e-01,
            1.19094886e-02,  1.07814811e-01, -2.00988099e-01,  1.47196427e-01,
           -3.30575407e-01,  1.77142993e-01,  1.41541317e-01, -5.74676931e-01,
            6.26891136e-01, -9.08448733e-03,  3.01960588e-01,  4.91884172e-01,
            9.31690156e-01,  5.47371805e-01, -1.70721978e-01, -1.41838700e-01,
           -8.38901475e-02, -2.05935732e-01,  1.37186851e-02,  8.66265148e-02,
            1.11656010e-01, -1.36832088e-01, -2.39025876e-01, -8.61346722e-02,
           -1.18631475e-01, -6.04380369e-01, -2.15705678e-01, -1.21428408e-02,
            1.54913977e-01,  1.24827653e-01, -2.44612187e-01,  3.71789515e-01,
           -1.60871133e-01, -1.51875302e-01, -5.64015269e-01, -3.08716953e-01,
           -1.67982921e-01,  1.27021670e-02,  2.52896454e-03, -1.59719393e-01,
           -1.25709428e-02, -3.50810885e-01, -2.77388275e-01,  1.43130552e-02,
            2.44775698e-01, -3.57535966e-02,  4.96162623e-01,  4.52934563e-01,
           -6.59682512e-01,  5.73042147e-02,  3.26564074e-01,  1.51106983e-01,
           -3.95536602e-01,  3.04116189e-01,  5.98153770e-01,  1.14780769e-01,
            1.15485869e-01,  5.72891593e-01, -3.16252053e-01, -2.30602831e-01,
            2.15535402e-01,  1.14284508e-01,  1.60032928e-01,  6.81623936e-01,
            3.37536365e-01, -4.05635983e-01,  2.18363509e-01, -2.09458731e-02,
           -1.68600664e-01,  2.75623977e-01, -2.99802348e-02,  2.28692424e-02,
           -1.46384001e-01,  5.26684463e-01,  4.41757679e-01,  6.12292998e-02,
            2.23614007e-01, -2.45505378e-01,  3.18603873e-01, -1.07176088e-01,
           -7.45218575e-01,  5.31067699e-02, -2.81688541e-01, -2.26904973e-01,
            3.33808869e-01,  2.18855459e-02, -2.28264630e-02, -2.09667850e-02,
            2.52372295e-01, -1.29880995e-01,  2.11536847e-02,  3.27383906e-01,
            1.48726091e-01, -3.87222623e-04,  1.09353639e-01, -1.12598769e-01,
           -1.89939946e-01, -2.24384770e-01,  2.63944596e-01, -7.81262293e-02,
           -9.49431658e-02, -5.48009813e-01, -3.33849698e-01,  8.96409154e-02,
           -1.09443903e-01,  6.64399564e-01, -3.40993464e-01,  3.89764398e-01,
            2.48190627e-01, -1.12249866e-01, -4.52181816e-01,  2.20591724e-01,
           -5.87389886e-01, -6.31692708e-01, -1.97141483e-01,  8.69040266e-02,
           -1.87570602e-02,  8.52509141e-02,  4.43617642e-01,  6.45090580e-01,
           -2.35322297e-01, -9.30620357e-02, -1.40743494e-01,  1.02335766e-01,
            3.40746194e-01,  2.31563702e-01, -1.85893580e-01,  1.33655444e-01,
            4.61917892e-02,  1.08569838e-01, -1.44024184e-02, -1.47935614e-01,
            8.89264047e-02,  7.47074857e-02, -4.07868624e-01, -3.82418305e-01,
            5.50290227e-01, -2.81685531e-01, -2.39913285e-01, -1.53242961e-01,
           -2.58827180e-01, -1.05847180e-01, -1.58128515e-01,  8.90466273e-02,
           -1.82038650e-03, -1.49243668e-01,  1.90218553e-01,  4.93904322e-01,
            3.22095044e-02,  4.68806326e-02,  1.10853136e-01,  1.13328099e-01,
           -2.54292171e-02,  1.44241145e-02, -1.34598732e-01,  1.00531451e-01,
           -2.85001695e-02, -6.23005211e-01,  1.60148814e-01,  9.68517885e-02,
           -4.37249184e-01,  6.43102050e-01, -3.22275519e-01,  2.95264661e-01,
           -3.75824600e-01,  2.72107422e-01,  1.28027484e-01, -7.13291913e-02,
           -1.74246386e-01, -1.75826594e-01, -1.78420529e-01,  2.41429999e-01,
            1.87329784e-01,  8.00989792e-02, -2.71158099e-01,  6.24268174e-01,
            6.17186911e-02, -7.63479108e-03, -7.83906952e-02,  4.22500730e-01,
            2.01404437e-01,  2.42894515e-01, -1.95990071e-01, -5.97726285e-01,
            1.11996360e-01,  1.70009479e-01,  3.25256288e-01, -4.49297190e-01,
            1.49387524e-01,  4.34649475e-02, -1.87276959e-01, -1.66159928e-01,
           -1.89135864e-01, -4.85989690e-01,  3.62226367e-01, -1.33195028e-01,
           -6.60636842e-01, -7.73904741e-01, -3.70514840e-01,  5.36868989e-01,
           -1.52960256e-01, -7.74044320e-02, -4.28031415e-01, -4.06813294e-01,
           -3.09568077e-01, -3.18129718e-01,  5.96830010e-01,  2.02072367e-01],
          dtype=float32)



## یافتن شباهت کسینوسی کاندیداها و کل متن
شباهت کسینوسی بین هریک از کاندیداها و وکتور نمایندهٔ متن را محاسبه می‌کنیم.


```python
candidates_sim_whole = cosine_similarity(all_candidates_vectors, whole_text_vector.reshape(1,-1))
candidates_sim_whole.reshape(1,-1)
```




    array([[ 1.19351953e-01,  1.23398483e-01,  1.25267982e-01,
             1.78353339e-02,  2.34080136e-01, -1.43648628e-02,
            -5.21925651e-03,  2.66611010e-01,  1.66823924e-01,
             1.12354815e-01, -1.51119381e-02,  1.41785324e-01,
             2.92644836e-03,  1.90887198e-01,  5.18489107e-02,
            -7.30122924e-02, -5.37125580e-02,  9.29163471e-02,
             1.13298275e-01,  1.23427741e-01,  1.57424986e-01,
             9.25901681e-02, -1.08412527e-01, -1.73858460e-02,
             2.51174212e-01,  2.12025747e-01,  5.75144589e-02,
             1.49892541e-02,  1.66313797e-01,  1.69365540e-01,
             8.05877075e-02,  1.91820011e-01,  1.14597335e-01,
             7.08760321e-02,  2.80742906e-02,  3.49122845e-02,
             7.90452361e-02,  2.57898092e-01, -1.49483442e-01,
             2.14596186e-02,  4.02773991e-02,  1.76318884e-02,
             1.82765976e-01, -1.09764189e-01,  1.59435749e-01,
             2.32247636e-04, -1.09125897e-01, -6.53942488e-03,
             4.97795194e-02]], dtype=float32)



## یافتن شباهت کسینوسی کاندیداها به یکدیگر
ماتریسی ایجاد می‌کنیم که هر درایهٔ آن با اندیس آی و جی، بیانگر شباهت کسینوسی کاندیدای آی با کاندیدای جی است.


```python
candidate_sim_candidate = cosine_similarity(all_candidates_vectors)
candidate_sim_candidate
```




    array([[0.9999997 , 0.14587443, 0.20270647, ..., 0.42830434, 0.27730745,
            0.30513293],
           [0.14587443, 0.9999996 , 0.10514447, ..., 0.48333895, 0.3179143 ,
            0.19037738],
           [0.20270647, 0.10514447, 1.        , ..., 0.47220594, 0.24125722,
            0.18565692],
           ...,
           [0.42830434, 0.48333895, 0.47220594, ..., 0.9999998 , 0.52577287,
            0.50683355],
           [0.27730745, 0.3179143 , 0.24125722, ..., 0.52577287, 0.99999964,
            0.40011758],
           [0.30513293, 0.19037738, 0.18565692, ..., 0.50683355, 0.40011758,
            0.9999996 ]], dtype=float32)



## نرمال‌سازی مقادیر مربوط به شباهت‌های کسینوسی
دو مقدار بالا را برای استفاده در مراحل بعد نرمال‌سازی می‌کنیم.


```python
candidates_sim_whole_norm = candidates_sim_whole / np.max(candidates_sim_whole)
candidates_sim_whole_norm = 0.5 + (candidates_sim_whole_norm - np.average(candidates_sim_whole_norm)) / np.std(candidates_sim_whole_norm)
candidates_sim_whole_norm
```




    array([[ 0.9393711 ],
           [ 0.979393  ],
           [ 0.9978831 ],
           [-0.06467056],
           [ 2.0740807 ],
           [-0.3831439 ],
           [-0.2926901 ],
           [ 2.3958247 ],
           [ 1.4088888 ],
           [ 0.87016654],
           [-0.3905328 ],
           [ 1.1612465 ],
           [-0.21212566],
           [ 1.6468846 ],
           [ 0.27173793],
           [-0.9631914 ],
           [-0.77230906],
           [ 0.677912  ],
           [ 0.8794977 ],
           [ 0.9796823 ],
           [ 1.3159292 ],
           [ 0.67468596],
           [-1.3133144 ],
           [-0.4130227 ],
           [ 2.2431483 ],
           [ 1.8559536 ],
           [ 0.32777256],
           [-0.09281945],
           [ 1.4038434 ],
           [ 1.4340265 ],
           [ 0.55597657],
           [ 1.6561104 ],
           [ 0.892346  ],
           [ 0.45992404],
           [ 0.03659701],
           [ 0.1042276 ],
           [ 0.54072094],
           [ 2.3096502 ],
           [-1.719523  ],
           [-0.02882487],
           [ 0.15729082],
           [-0.0666827 ],
           [ 1.5665622 ],
           [-1.326683  ],
           [ 1.3358166 ],
           [-0.23877239],
           [-1.3203701 ],
           [-0.3057471 ],
           [ 0.25127074]], dtype=float32)




```python
np.fill_diagonal(candidate_sim_candidate, np.NaN)
candidate_sim_candidate_norm = candidate_sim_candidate / np.nanmax(candidate_sim_candidate, axis=0)
candidate_sim_candidate_norm = 0.5 + (candidate_sim_candidate_norm - np.nanmean(candidate_sim_candidate_norm, axis=0)) / np.nanstd(candidate_sim_candidate_norm, axis=0)
candidate_sim_candidate_norm
```




    array([[           nan, -3.5498703e-01,  3.2357961e-02, ...,
             1.8948689e-01,  3.9502221e-01,  6.2098056e-01],
           [-5.2607918e-01,            nan, -7.2487104e-01, ...,
             4.3979204e-01,  6.8422610e-01, -9.5400155e-02],
           [-1.7625093e-02, -6.8133366e-01,            nan, ...,
             3.8915750e-01,  1.3827083e-01, -1.2486839e-01],
           ...,
           [ 2.0007110e+00,  2.3489289e+00,  2.1240823e+00, ...,
                       nan,  2.1646044e+00,  1.8801302e+00],
           [ 6.4980078e-01,  1.0234730e+00,  3.3157024e-01, ...,
             6.3278729e-01,            nan,  1.2139380e+00],
           [ 8.9874434e-01,  1.5904903e-03, -9.9972427e-02, ...,
             5.4664868e-01,  1.2696817e+00,            nan]], dtype=float32)



## استخراج کلمات کلیدی از روی شباهت‌های کسینوسی
با استفاده از روش امبدرنک در یک الگوریتم تکرارشونده، در هر مرحله با یک فرمول، یک کاندیدا به عنوان کلمهٔ کلیدی انتخاب می‌شود.
کاندیدایی انتخاب می‌شود که در درجهٔ اول بیشترین شباهت را با کل متن دارد و در درجهٔ دوم کمترین شباهت را با کاندیداهای انتخاب‌شده دارد.
میزان اثرگذاری این دو فاکتور را می‌توان با درنظرگرفتن عوامل مختلفی مثل طول و محتوای متن تغییر داد.
(beta)


```python
beta = 0.82
N = min(len(all_candidates), keyword_count)

selected_candidates = []
unselected_candidates = [i for i in range(len(all_candidates))]
best_candidate = np.argmax(candidates_sim_whole_norm)
selected_candidates.append(best_candidate)
unselected_candidates.remove(best_candidate)


for i in range(N-1):
    selected_vec = np.array(selected_candidates)
    unselected_vec = np.array(unselected_candidates)
    
    unselected_candidate_sim_whole_norm = candidates_sim_whole_norm[unselected_vec, :]
    
    dist_between = candidate_sim_candidate_norm[unselected_vec][:, selected_vec]
    
    if dist_between.ndim == 1:
        dist_between = dist_between[:, np.newaxis]
    
    best_candidate = np.argmax(beta * unselected_candidate_sim_whole_norm - (1 - beta) * np.max(dist_between, axis = 1).reshape(-1,1))
    best_index = unselected_candidates[best_candidate]
    selected_candidates.append(best_index)
    unselected_candidates.remove(best_index)
all_candidates[selected_candidates].tolist()
```




    ['معنی بی‌احترامی',
     'دلایل تشریفاتی',
     'سطح ملکه',
     'توضیح مذهبی',
     'نشریه اسپانیایی',
     'زن',
     'مراسم سال',
     'فیلم',
     'کارشناس رسمی',
     'کشور']


